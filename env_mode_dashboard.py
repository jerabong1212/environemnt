# -*- coding: utf-8 -*-
"""
env_mode_dashboard.py
Streamlit app for environmental data analysis with 3 main modes:
1) Temperature
2) Humidity
3) Light  (Intensity / Photoperiod / Daily Cumulative (DLI-like))

Assumptions
- Data contain a time-like column (auto-detected) and numeric sensor columns.
- Light "on" is detected by a threshold (default > 0). You can change it.
- Sampling interval is inferred from median delta between timestamps (works with 10-min data).

Author: generated collaboratively
"""

import io
from typing import Optional, Tuple, List, Dict
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

# ------------------------------
# Page setup
# ------------------------------
st.set_page_config(page_title="í™˜ê²½ ë°ì´í„° 3ëª¨ë“œ ë¶„ì„", layout="wide")
st.title("ğŸŒ¿ í™˜ê²½ ë°ì´í„° 3ëª¨ë“œ ë¶„ì„ (ì—…ë¡œë“œ ê¸°ë°˜)")

# ------------------------------
# Helpers
# ------------------------------
def _norm(s: str) -> str:
    return str(s).strip().lower().replace("_"," ").replace("-"," ")

def detect_time_column(df: pd.DataFrame) -> Optional[str]:
    cand = [c for c in df.columns if any(k in _norm(c) for k in ["time","date","timestamp","datetime","ì¼ì‹œ","ì‹œê°","ì¸¡ì •"])]
    scores = []
    for c in df.columns:
        try:
            parsed = pd.to_datetime(df[c], errors="coerce", infer_datetime_format=True)
            scores.append((c, parsed.notna().mean()))
        except Exception:
            scores.append((c, 0.0))
    def key(x): return (x[0] in cand, x[1])
    scores.sort(key=key, reverse=True)
    return scores[0][0] if scores and scores[0][1] > 0.5 else None

@st.cache_data(show_spinner=False)
def read_any(file_bytes: bytes, file_name: str) -> pd.DataFrame:
    ext = str(file_name).lower().split(".")[-1]
    if ext == "csv":
        return pd.read_csv(io.BytesIO(file_bytes))
    else:
        # Excel: merge all sheets
        xlf = pd.ExcelFile(io.BytesIO(file_bytes))
        frames = []
        for s in xlf.sheet_names:
            try:
                df = xlf.parse(s)
                df["__Sheet__"] = s
                frames.append(df)
            except Exception:
                pass
        return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()

def coerce_time(df: pd.DataFrame, tcol: str) -> pd.DataFrame:
    out = df.copy()
    out["Timestamp"] = pd.to_datetime(out[tcol], errors="coerce", infer_datetime_format=True)
    out = out.dropna(subset=["Timestamp"]).sort_values("Timestamp")
    return out

def infer_interval_seconds(ts: pd.Series) -> Optional[float]:
    diffs = ts.sort_values().diff().dropna()
    if diffs.empty:
        return None
    return float(diffs.dt.total_seconds().median())

def choose_numeric_columns(df: pd.DataFrame, exclude: List[str]) -> List[str]:
    return [c for c in df.columns if c not in exclude and pd.api.types.is_numeric_dtype(df[c])]

def bar_with_error(mean_val: float, std_val: float, title: str, y_label: str = ""):
    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=[title],
        y=[mean_val],
        error_y=dict(type='data', array=[std_val]),
        name="Mean Â± SD"
    ))
    fig.update_layout(yaxis_title=y_label, showlegend=False)
    return fig

# Photoperiod detection: first-on & last-off per day
def photoperiod_table(df: pd.DataFrame, light_col: str, on_thr: float, interval_sec: Optional[float]) -> pd.DataFrame:
    tmp = df[["Timestamp", light_col]].dropna().copy()
    tmp["date"] = tmp["Timestamp"].dt.date
    tmp["is_on"] = tmp[light_col] > on_thr
    day_list = []
    step_sec = interval_sec if interval_sec is not None else 600.0  # default 10min
    for d, sub in tmp.groupby("date"):
        if not sub["is_on"].any():
            day_list.append({"Date": d, "On Time": None, "Off Time": None, "Photoperiod (h)": 0.0, "Segments": 0})
            continue
        # segments detection via run-length on is_on
        segs = []
        cur_on = None
        for t, flag in zip(sub["Timestamp"].tolist(), sub["is_on"].tolist()):
            if flag and cur_on is None:
                cur_on = t
            elif not flag and cur_on is not None:
                segs.append((cur_on, t))
                cur_on = None
        if cur_on is not None:
            # closing open segment; approximate off at last time + one step
            last_t = sub["Timestamp"].iloc[-1]
            off_t = last_t + pd.to_timedelta(step_sec, unit="s")
            segs.append((cur_on, off_t))
        first_on = segs[0][0] if segs else None
        last_off = segs[-1][1] if segs else None
        total_h = sum([(b - a).total_seconds() for a, b in segs]) / 3600.0 if segs else 0.0
        day_list.append({
            "Date": d,
            "On Time": first_on,
            "Off Time": last_off,
            "Photoperiod (h)": round(total_h, 3),
            "Segments": len(segs)
        })
    return pd.DataFrame(day_list).sort_values("Date")

def daily_cumulative(df: pd.DataFrame, light_col: str, interval_sec: Optional[float], only_when_on: bool, on_thr: float) -> pd.DataFrame:
    tmp = df[["Timestamp", light_col]].dropna().copy()
    if only_when_on:
        tmp = tmp[tmp[light_col] > on_thr]
    tmp["date"] = tmp["Timestamp"].dt.date
    step = interval_sec if interval_sec is not None else 600.0  # seconds
    # integral = sum(light * dt)
    daily = tmp.groupby("date")[light_col].sum() * step
    daily = daily.rename("DailyIntegral")
    out = daily.reset_index().rename(columns={"date":"Date"})
    return out

# ------------------------------
# Sidebar: Upload & mapping
# ------------------------------
with st.sidebar:
    st.header("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
    up = st.file_uploader("í™˜ê²½ ë°ì´í„° ì—…ë¡œë“œ (xlsx/xls/csv)", type=["xlsx","xls","csv"])

if up is None:
    st.info("ì™¼ìª½ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    st.stop()

df_raw = read_any(up.getvalue(), up.name)
if df_raw.empty:
    st.warning("ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# Time column detection & coercion
tcol_auto = detect_time_column(df_raw)
time_col = st.sidebar.selectbox("ì‹œê°„ ì»¬ëŸ¼ ì„ íƒ", options=["<ìë™ íƒì§€>"] + df_raw.columns.tolist(), index=0)
if time_col == "<ìë™ íƒì§€>":
    time_col = tcol_auto
if time_col is None:
    st.warning("ì‹œê°„ ì»¬ëŸ¼ì„ ìë™ìœ¼ë¡œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì§ì ‘ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    st.stop()

df = coerce_time(df_raw, time_col)

# Numeric columns & mapping
exclude_cols = ["Timestamp","__Sheet__"]
num_cols = choose_numeric_columns(df, exclude=exclude_cols)
st.sidebar.markdown("---")
st.sidebar.header("ğŸ§­ ë³€ìˆ˜ ë§¤í•‘")
temp_col = st.sidebar.selectbox("ì˜¨ë„ ì»¬ëŸ¼", options=["<ì—†ìŒ>"] + num_cols, index=0)
rh_col   = st.sidebar.selectbox("ìŠµë„ ì»¬ëŸ¼", options=["<ì—†ìŒ>"] + num_cols, index=0)
light_col= st.sidebar.selectbox("ê´‘ ì»¬ëŸ¼", options=["<ì—†ìŒ>"] + num_cols, index=0)

# Date range
st.sidebar.markdown("---")
st.sidebar.header("â±ï¸ ê¸°ê°„ í•„í„°")
min_t, max_t = df["Timestamp"].min(), df["Timestamp"].max()
sel_range = st.sidebar.slider("ê¸°ê°„ ì„ íƒ", value=(min_t, max_t), min_value=min_t, max_value=max_t, format="YYYY-MM-DD HH:mm")

df = df[(df["Timestamp"] >= sel_range[0]) & (df["Timestamp"] <= sel_range[1])].copy()
if df.empty:
    st.warning("ì„ íƒí•œ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# Sampling interval
interval_sec = infer_interval_seconds(df["Timestamp"])

# ------------------------------
# Main Mode
# ------------------------------
mode = st.selectbox("ë¶„ì„ ëª¨ë“œ ì„ íƒ", ["ì˜¨ë„", "ìŠµë„", "ê´‘"], index=0)

# ---------- ì˜¨ë„ ----------
if mode == "ì˜¨ë„":
    if temp_col == "<ì—†ìŒ>":
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ ì˜¨ë„ ì»¬ëŸ¼ì„ ì§€ì •í•˜ì„¸ìš”.")
        st.stop()
    series = df[["Timestamp", temp_col]].dropna()
    mean_val = float(series[temp_col].mean())
    std_val  = float(series[temp_col].std())
    c1, c2 = st.columns([1,2])
    with c1:
        st.subheader("ğŸ“Š í‰ê· Â±í‘œì¤€í¸ì°¨ (ë§‰ëŒ€)")
        st.plotly_chart(bar_with_error(mean_val, std_val, "Temperature", y_label=temp_col), use_container_width=True)
        st.caption(f"ê¸°ê°„ í‰ê· : **{mean_val:.3f}**, í‘œì¤€í¸ì°¨: **{std_val:.3f}**")
    with c2:
        st.subheader("ğŸ“ˆ ì‹œê³„ì—´ ê·¸ë˜í”„")
        fig = px.line(series, x="Timestamp", y=temp_col, title=f"{temp_col} ì‹œê°„ ë³€í™”")
        st.plotly_chart(fig, use_container_width=True)

# ---------- ìŠµë„ ----------
elif mode == "ìŠµë„":
    if rh_col == "<ì—†ìŒ>":
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ ìŠµë„ ì»¬ëŸ¼ì„ ì§€ì •í•˜ì„¸ìš”.")
        st.stop()
    series = df[["Timestamp", rh_col]].dropna()
    mean_val = float(series[rh_col].mean())
    std_val  = float(series[rh_col].std())
    c1, c2 = st.columns([1,2])
    with c1:
        st.subheader("ğŸ“Š í‰ê· Â±í‘œì¤€í¸ì°¨ (ë§‰ëŒ€)")
        st.plotly_chart(bar_with_error(mean_val, std_val, "Humidity", y_label=rh_col), use_container_width=True)
        st.caption(f"ê¸°ê°„ í‰ê· : **{mean_val:.3f}**, í‘œì¤€í¸ì°¨: **{std_val:.3f}**")
    with c2:
        st.subheader("ğŸ“ˆ ì‹œê³„ì—´ ê·¸ë˜í”„")
        fig = px.line(series, x="Timestamp", y=rh_col, title=f"{rh_col} ì‹œê°„ ë³€í™”")
        st.plotly_chart(fig, use_container_width=True)

# ---------- ê´‘ ----------
else:
    if light_col == "<ì—†ìŒ>":
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ ê´‘ ì»¬ëŸ¼ì„ ì§€ì •í•˜ì„¸ìš”.")
        st.stop()

    st.markdown("### ğŸ”¦ ê´‘ ë¶„ì„ ì„œë¸Œëª¨ë“œ")
    submode = st.radio("ì„œë¸Œëª¨ë“œ ì„ íƒ", ["1) ê´‘ë„", "2) ê´‘ì£¼ê¸°", "3) ì ì‚°ê´‘ë„"], horizontal=True)

    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ’¡ ê´‘ íŒŒë¼ë¯¸í„°")
    on_thr = st.sidebar.number_input("Light ON ì„ê³„ê°’(ì´ˆê³¼)", value=0.0, step=0.1, help="ì´ ê°’ ì´ˆê³¼ë¥¼ ì¼œì§ìœ¼ë¡œ ê°„ì£¼")
    only_on_for_intensity = True  # for mode 1
    convert_to_dli = st.sidebar.checkbox("PPFD(Î¼mol mâ»Â² sâ»Â¹) â†’ DLI(ëª° mâ»Â² ì¼â»Â¹) ë³€í™˜", value=False, help="ì ì‚° ì‹œ 1e6ìœ¼ë¡œ ë‚˜ëˆ”")

    if submode.startswith("1"):
        # Intensity (lights on only)
        sub = df[["Timestamp", light_col]].dropna()
        sub = sub[sub[light_col] > on_thr]
        if sub.empty:
            st.info("ì„ê³„ê°’ ì´ˆê³¼ êµ¬ê°„(ì¼œì§)ì´ ì—†ìŠµë‹ˆë‹¤. ì„ê³„ê°’ì„ ì¡°ì •í•´ ë³´ì„¸ìš”.")
        else:
            mean_val = float(sub[light_col].mean())
            std_val  = float(sub[light_col].std())
            c1, c2 = st.columns([1,2])
            with c1:
                st.subheader("ğŸ“Š ì¼œì§ êµ¬ê°„ ê´‘ë„ í‰ê· Â±í‘œì¤€í¸ì°¨")
                st.plotly_chart(bar_with_error(mean_val, std_val, "Light Intensity", y_label=light_col), use_container_width=True)
                st.caption(f"ì¼œì§ êµ¬ê°„ í‰ê· : **{mean_val:.3f}**, í‘œì¤€í¸ì°¨: **{std_val:.3f}** (ì„ê³„ê°’ {on_thr} ì´ˆê³¼ ë°ì´í„°ë§Œ ì‚¬ìš©)")
            with c2:
                st.subheader("ğŸ“ˆ ì‹œê³„ì—´(ì¼œì§ êµ¬ê°„ë§Œ)")
                fig = px.line(sub, x="Timestamp", y=light_col, title=f"{light_col} ì‹œê°„ ë³€í™” (ONë§Œ)")
                st.plotly_chart(fig, use_container_width=True)

    elif submode.startswith("2"):
        # Photoperiod table
        st.subheader("ğŸ•‘ ê´‘ì£¼ê¸°(Photoperiod) ì¼ìë³„ í‘œ")
        table = photoperiod_table(df, light_col, on_thr=on_thr, interval_sec=interval_sec)
        st.dataframe(table, use_container_width=True)
        # Download
        csv_bytes = table.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ê´‘ì£¼ê¸° í‘œ CSV ë‹¤ìš´ë¡œë“œ", data=csv_bytes, file_name="photoperiod_table.csv", mime="text/csv")
        if interval_sec is not None:
            st.caption(f"ì¶”ì • ìƒ˜í”Œë§ ê°„ê²©: **{interval_sec:.0f}ì´ˆ**")

    else:
        # Daily cumulative (DLI-like)
        st.subheader("â˜€ï¸ ì ì‚°ê´‘ë„")
        day_int = daily_cumulative(df, light_col, interval_sec=interval_sec, only_when_on=False, on_thr=on_thr)
        if day_int.empty:
            st.info("ì ì‚° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # Optional conversion to DLI (if PPFD provided)
            if convert_to_dli:
                day_int["DailyIntegral"] = day_int["DailyIntegral"] / 1_000_000.0
                unit_label = "DLI (mol mâ»Â² dâ»Â¹)"
            else:
                unit_label = f"{light_col}Ã—s (ì ë¶„ê°’)"
            day_int = day_int.rename(columns={"DailyIntegral": unit_label})

            # Per-day plot
            fig = px.bar(day_int, x="Date", y=unit_label, title="ì¼ë³„ ì ì‚°ê´‘ë„", text_auto=True)
            st.plotly_chart(fig, use_container_width=True)

            # Mean Â± SD across days
            mean_val = float(day_int[unit_label].mean())
            std_val  = float(day_int[unit_label].std())
            st.subheader("ğŸ“Š ì „ì²´ ê¸°ê°„ì˜ í‰ê·  ì¼ì¼ ì ì‚°ê´‘ë„ (Mean Â± SD)")
            st.plotly_chart(bar_with_error(mean_val, std_val, "Daily Cumulative", y_label=unit_label), use_container_width=True)
            st.caption(f"í‰ê· : **{mean_val:.3f}**, í‘œì¤€í¸ì°¨: **{std_val:.3f}**")

            # Download
            csv_bytes = day_int.to_csv(index=False).encode("utf-8-sig")
            st.download_button("ì¼ë³„ ì ì‚°ê´‘ë„ CSV ë‹¤ìš´ë¡œë“œ", data=csv_bytes, file_name="daily_cumulative_light.csv", mime="text/csv")
            if interval_sec is not None:
                st.caption(f"ì¶”ì • ìƒ˜í”Œë§ ê°„ê²©: **{interval_sec:.0f}ì´ˆ**")
